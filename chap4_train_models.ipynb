{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a689d0-54b5-4d04-b916-29f36f52746c",
   "metadata": {},
   "source": [
    "### Train Model Experiments NB \n",
    "This notebook contains the code to split the images and load them into train and validate sets.  The notebook also has the definition for the way the data should be loaded for each of six computer vision model types.  The notebook uses the concept of experiments to organize the fit/validate activities and allow for hyperparameter searching and logging results.  \n",
    "\n",
    "Scroll down to the head \"Experiments\" and add your experiment as a new cell underneath the heading, modify the experiment meta data and run the cell.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dae7bf88-623d-49ab-ae35-c883cbe00ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries for training, testing, validation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import imagenet_utils  # will decode predictions out of the model into a 4 dim array of N (image num), imageID, label, probability result[0] would be the set of results for image one\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img  # will load img and reshape, usage is load_img(image_name_loc, target_size=input_shape)\n",
    "from tensorflow.keras.utils import plot_model  # Note: usage syntax is plot_model(instantied_model, to_file='', show_shapes=True)\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds  # For loading datasets from GCS\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# add capabilities to generate data and stop early as well as regulation options to avoid over fitting per experiment #1\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# import all model architectures\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Large, MobileNetV3Small\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "# suppress warnings\n",
    "from absl import logging  # tensorflow internal log\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9397c79d-8cba-44fd-b8bc-a367d54bad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary for model config and experiment tracking.... \n",
    "# define global variables\n",
    "gcs_bucket = 'nabirds_filtered'  \n",
    "dataset_path = 'images'  # Relative path within the bucket\n",
    "default_batch_size = 32\n",
    "default_image_size = (224, 224)\n",
    "\n",
    "model_input_variables = {'MobileNetV2': {'input_shape': (224, 224, 3), 'batch_size': 32,},\n",
    "     'MobileNetV3Large': {'input_shape': (224, 224, 3),'batch_size': 32,},\n",
    "    'MobileNetV3Small':{'input_shape': (224, 224, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB0': {'input_shape': (224, 224, 3), 'batch_size': 32,},\n",
    "    'InceptionV3': {'input_shape': (299, 299, 3), 'batch_size': 32,}, # InceptionV3 typically uses 299x299\n",
    "    'EfficientNetB7':{'input_shape': (600, 600, 3), 'batch_size': 16,}, # this is a larger model and the norm seems to be smaller batch sizes for reduced memory use\n",
    "    'EfficientNetB1': {'input_shape': (240, 240, 3), 'batch_size': 32,},  # added 1 thru 6 during experiment 3\n",
    "    'EfficientNetB2': {'input_shape': (288, 288, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB3': {'input_shape': (300, 300, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB4': {'input_shape': (380, 380, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB5': {'input_shape': (456, 456, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB6': {'input_shape': (528, 528, 3), 'batch_size': 32,}\n",
    "}\n",
    "models_list = list(model_input_variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c6a513-1aad-4763-a833-c0eae28c78bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_results_to_file(filename, experiment, start_time, end_time, model_name, epochs, \n",
    "                          training_accuracy, validate_accuracy, training_loss, validate_loss,\n",
    "                          num_stages, stage1, stage2):\n",
    "    start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    batch_size = str(model_input_variables[model_name]['batch_size'])\n",
    "    input_shape = str(model_input_variables[model_name]['input_shape']).replace(',','x')\n",
    "    stage1 = f\"stage1 epochs:{stage1['epochs']} trainable: {stage1['base_trainable']} trainable layers: {stage1['trainable_layers']} learning rate: {stage1['learning_rate']}\"\n",
    "    stage2 = f\"stage2 epochs:{stage2['epochs']} trainable: {stage2['base_trainable']} trainable layers: {stage2['trainable_layers']} learning rate: {stage2['learning_rate']}\"\n",
    "    line = f'{experiment},{start_time_str},{end_time_str},{model_name},{batch_size},{epochs},{input_shape},{training_accuracy},' \\\n",
    "           f'{validate_accuracy},{training_loss},{validate_loss},{num_stages},{stage1},{stage2}\\n'\n",
    "    if not os.path.exists(filename):      # Check if the file exists, and add a header if it's new\n",
    "        header = 'experiment,start_time,end_time,model_name,batch_size,epochs,input_shape,training_accuracy,validate_accuracy,training_loss,validate_loss,num_stages,stage1,stage2\\n'\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(header + line)\n",
    "    else:\n",
    "        with open(filename, \"a\") as f: # append to existing file\n",
    "            f.write(line)\n",
    "    print(f'experiment tracking updated')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "293b3f33-f2f5-4147-a979-ee49b8c50341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images_gcs(bucket_name, dataset_path, model_image_size, model_batch_size):\n",
    "    dataset = None\n",
    "    gcs_dataset_path = f\"gs://{bucket_name}/{dataset_path}\"\n",
    "    try:\n",
    "        dataset = keras.utils.image_dataset_from_directory(gcs_dataset_path, image_size=model_image_size,\n",
    "            batch_size=model_batch_size, label_mode='categorical',)  # categorical is for softmax layer\n",
    "    except Exception as e:\n",
    "        print(f'error loading dataset from gcs: {e}')    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3637ff1b-af98-4d1b-ab03-5fcf0051e528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into its own cell so we do not have to repeat this long operation, takes 10 minutes....\n",
    "# need to run this each time for different image and batch sizes\n",
    "def load_images(image_size=default_image_size, batch_size=default_batch_size):\n",
    "    start_time = time.time()\n",
    "    start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "    print(f'Start loading images time: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'Loading with image size of {image_size} and batch size of {batch_size}')\n",
    "\n",
    "    train_dataset = load_images_gcs(gcs_bucket, os.path.join(dataset_path, 'train'), image_size, batch_size)\n",
    "    validate_dataset = load_images_gcs(gcs_bucket, os.path.join(dataset_path, 'test'), image_size, batch_size)\n",
    "\n",
    "    if train_dataset is None or validate_dataset is None:\n",
    "        print(f'dataset loading failed.')\n",
    "    return train_dataset, validate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89bccfe4-decc-4edf-9120-e82ccfe42360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_results(acc, validate_acc, loss, validate_loss):\n",
    "    epochs_plt = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_plt, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs_plt, validate_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_plt, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs_plt, validate_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bc17b88-aae1-4546-8266-c7618ad6ebe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lock and unlock layers, make this bullet proof so I don't have to think about the experiments too much\n",
    "def lock_unlock_layers(model, train_last_x_layers):\n",
    "    train_last_x_layers = 0 if train_last_x_layers == None else train_last_x_layers\n",
    "    fine_tune_at = len(model.layers) - abs(train_last_x_layers)                        \n",
    "    fine_tune_at = 0 if fine_tune_at < 0 else fine_tune_at\n",
    "    for layer in model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cfa5d68-42f8-4a13-947d-160b04046aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model_experiment(experiment_name, model_name, stages, stage1, stage2, train_dataset, validate_dataset, num_classes, log_record):\n",
    "    stage1_learning = stage1[\"learning_rate\"]\n",
    "    stage1_epochs = stage1[\"epochs\"]\n",
    "    stage1_base_trainable = stage1['base_trainable']\n",
    "    stage1_trainable_layers = stage1['trainable_layers']\n",
    "    stage2_learning = stage2[\"learning_rate\"]\n",
    "    stage2_epochs = stage2[\"epochs\"]\n",
    "    stage2_base_trainable = stage2['base_trainable']\n",
    "    stage2_trainable_layers = stage2['trainable_layers']\n",
    "    \n",
    "    start_time = time.time()\n",
    "    start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "    print(f'Start time training and validation: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'building model: {model_name} with {stages} stage(s)')\n",
    "    print(f'stage1... ')\n",
    "    print(f'epochs: {stage1_epochs}')\n",
    "    print(f'learning rate of {stage1_learning}')\n",
    "    print(f'trainable: {stage1_base_trainable}')\n",
    "    print(f'trainable_layers: {stage1_trainable_layers}')\n",
    "    \n",
    "     # load each mode type and modify head for softmax replacement\n",
    "    if model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "    elif model_name == 'MobileNetV3Large':\n",
    "        base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "    elif model_name == 'MobileNetV3Small':\n",
    "        base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'InceptionV3':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(229, 229, 3))\n",
    "    elif model_name == 'EfficientNetB7':\n",
    "        base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(600, 600, 3))\n",
    "    elif model_name == 'EfficientNetB1':\n",
    "        base_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n",
    "    elif model_name == 'EfficientNetB2':\n",
    "        base_model = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(288, 288, 3))\n",
    "    elif model_name == 'EfficientNetB3':\n",
    "        base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "    else:\n",
    "        print(f'unknown model {model_name} inf run_model_experiment case statement')\n",
    "\n",
    "    ### setup call backs and other admin...\n",
    "    # save best model, save model when monitored metric improved, 'max' for accuracy, 'min' for loss\n",
    "    # callbacks early stopping and learning rate reduction\n",
    "    # suppress warnings\n",
    "    model_filename = experiment_name + model_name + '.h5'\n",
    "    # model_checkpoint_callback = ModelCheckpoint(filepath=model_filename, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)  # added save weights for efficientnet\n",
    "    model_checkpoint_callback = ModelCheckpoint(filepath=model_filename, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1, save_weights_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    \n",
    "    #####  setup stage 1 of X #####\n",
    "    base_model.trainable = stage1_base_trainable  # true unlocks the entire model\n",
    "    if stage1_base_trainable is False and stage1_trainable_layers != None:  # false a number unlocks the last x layers\n",
    "        base_model = lock_unlock_layers(model=base_model, train_last_x_layers=stage1_trainable_layers)\n",
    "    x = base_model.output  # start adding custom layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)  \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # create the model with rescaling layer, this will automatically normalize the images within the model, bulletproofs feeder code\n",
    "    # normalize pixel values to [0, 1], not sure if this was done in the old mobilenetv2 model\n",
    "    inputs = base_model.input\n",
    "    rescaled_inputs = tf.keras.layers.Rescaling(1./255)(inputs)  \n",
    "    augmentation_layers = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomShear(0.2), \n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1), \n",
    "    ])\n",
    "    augmented_inputs = augmentation_layers(rescaled_inputs) \n",
    "    x = base_model(augmented_inputs) \n",
    "    model = Model(inputs=inputs, outputs=predictions) # use original inputs\n",
    "        \n",
    "    # compile and train model, epoch zero is starting place for first stage, categorical crossentropy is for multi-class classification\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=stage1_learning), loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    history_phase1 = model.fit(train_dataset, epochs=stage1_epochs, initial_epoch=0, validation_data=validate_dataset, \n",
    "                               callbacks=[model_checkpoint_callback, early_stopping, reduce_lr] )  \n",
    "\n",
    "    ##### setup stage 2 if requested\n",
    "    combined_history = {}\n",
    "    print(f'history 1 keys: {history_phase1.history.keys()}')\n",
    "    if stages == 2:\n",
    "        print(f'stage2...')\n",
    "        model = lock_unlock_layers(model=model, train_last_x_layers=stage2_trainable_layers)\n",
    "        # Recompile the model and continue from phase1, last epoch + 1 to move to next available \n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=stage2_learning), loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        history_phase2 = model.fit(train_dataset, epochs=stage1_epochs + stage2_epochs, initial_epoch=stage1_epochs, validation_data=validate_dataset,\n",
    "                                  callbacks=[model_checkpoint_callback, early_stopping, reduce_lr])   \n",
    "        print(f'history2 keys: {history_phase2.history.keys()}')\n",
    "        for key in history_phase1.history:  # combine history\n",
    "            try:\n",
    "                combined_history[key] = history_phase1.history[key] + history_phase2.history[key]\n",
    "            except:\n",
    "                pass\n",
    "                #     print(f'history1 key {key} not found in history2 ')\n",
    "        for key2 in history_phase2.history:\n",
    "            if key2 not in history_phase1.history:\n",
    "                combined_history[key2] = history_phase2.history[key2]\n",
    "    else:\n",
    "        stage2_epochs=0\n",
    "        combined_history = history_phase1.history  # if one state take stage 1 hist    \n",
    "                \n",
    "    #### process results and save model\n",
    "    # Load the best weights saved by the ModelCheckpoint callback, save the entire model (architecture + weights)\n",
    "    try:\n",
    "        model.save(model_filename)\n",
    "        # model.load_weights(model_filename)\n",
    "        # keras.models.save_model(model, model_filename)\n",
    "        print(f'model saved to: {model_filename}')\n",
    "    except Exception as e:\n",
    "        print(f'model save failed with error {e}')\n",
    "    \n",
    "    # record training time\n",
    "    end_time = time.time()\n",
    "    end_time_datetime = datetime.datetime.fromtimestamp(end_time)\n",
    "    print(f'End time training and validation: {end_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "    # write_results_to_file\n",
    "    total_epochs = stage1_epochs + stage2_epochs\n",
    "    acc = combined_history['accuracy']\n",
    "    validate_acc = combined_history['val_accuracy']\n",
    "    loss = combined_history['loss']\n",
    "    validate_loss = combined_history['val_loss']\n",
    "\n",
    "    if log_record:\n",
    "        write_results_to_file('experiment_log.csv', experiment_name, start_time_datetime, end_time_datetime, model_name, total_epochs, \n",
    "                              acc[-1], validate_acc[-1], loss[-1], validate_loss[-1], stages, stage1, stage2)\n",
    "    plot_training_results(acc, validate_acc, loss, validate_loss) \n",
    "    return acc, validate_acc, loss, validate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501839b-a05c-423e-971e-d759809acdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc7d276b-dcc1-4589-b863-3bb9e84946f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the experiments dictionary drives the model types and training parameters \n",
    "# loop over each model type, stages, and write out results of experiment to a file, save the model\n",
    "def run_experiments(experiments, train_dataset, validate_dataset, num_classes, log_record=True):\n",
    "    for exper in list(experiments.keys()):\n",
    "        stages = experiments[exper]['number_of_stages']\n",
    "        stage1 = experiments[exper]['stage1']\n",
    "        stage2 = experiments[exper]['stage2']\n",
    "        \n",
    "        for model_num in experiments[exper]['model_types']:\n",
    "            model_name = models_list[model_num]\n",
    "            acc, validate_acc, loss, validate_loss = run_model_experiment(exper, model_name, stages, stage1, stage2, \n",
    "                                                                          train_dataset, validate_dataset, num_classes, \n",
    "                                                                         log_record)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96d76ca-7817-4ca6-9186-e869b6e9d293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading images time: 2025-04-09 22:01:19\n",
      "Loading with image size of (224, 224) and batch size of 32\n",
      "Found 2455 files belonging to 27 classes.\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f96b40cd1b0> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.string, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.string, name=None),)] [kwargs: {}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f96b40ceb00> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.int32, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.int32, name=None),)] [kwargs: {}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 22:05:53.874094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:53.907314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:53.907580: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:53.908350: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-09 22:05:53.909806: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:53.910047: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:53.910233: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:54.107090: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:54.107345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:54.107521: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-09 22:05:54.107675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 146 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 files belonging to 27 classes.\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f96b40ceb00> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.string, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.string, name=None),)] [kwargs: {}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f96b40cea70> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.int32, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.int32, name=None),)] [kwargs: {}]\n"
     ]
    }
   ],
   "source": [
    "# load the default data 224x224x3 ,batch size 32 data set.  do not loop over this code unless its an exception. \n",
    "# takes about 10 minutes, note this will output warning/errors since this NB is not using a GPU\n",
    "# request a different load for a different model size, copy and paste code and change parameters\n",
    "default_train_dataset, default_validate_dataset = load_images()\n",
    "num_classes = len(default_train_dataset.class_names) # get class count, same no mater how the data is loaded given the same data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90a34f-90d0-40c1-9a77-8a32b37ddbeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiments\n",
    "quick primer:  \n",
    "Accuracy: overall proportion of correct predictions (both true positives and true negatives) out of all predictions made.\n",
    "Formula: (True Positives + True Negatives) / (Total Predictions)\n",
    "Precision: measures the proportion of true positive predictions out of all positive predictions made by the model.\n",
    "Formula: True Positives / (True Positives + False Positives)\n",
    "Recall (also known as Sensitivity): measures the proportion of actual positive instances that the model correctly identified.\n",
    "Formula: True Positives / (True Positives + False Negatives)\n",
    "\n",
    "- Early experiment: learning_rate to low resulted in overfitting .001 with 50 epochs.  Added code to save best model since the results detoritated as more epochs were applied.  added libraries to generate more images if needed and for early stopping and learning rate reduction.  not in code yet \n",
    "- Experiment1: lowered learning rate to .0001 and trained for 25 epochs.  much better result.\n",
    "- Experiment2: incorporated early stopping code and learning rate reduction and increased epochs to 50.  future: add regulaziation and drop out layers? add more training images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1025d43-4a0f-4b7d-acd8-6a700105079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['MobileNetV2', 'MobileNetV3Large', 'MobileNetV3Small', 'EfficientNetB0', 'InceptionV3', 'EfficientNetB7', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3', 'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6']\n",
      "EfficientNetB0: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "MobileNetV2: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "MobileNetV3Large: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "MobileNetV3Small: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "InceptionV3: {'input_shape': (299, 299, 3), 'batch_size': 32}\n",
      "EfficientNetB7: {'input_shape': (600, 600, 3), 'batch_size': 16}\n",
      "EfficientNetB1: {'input_shape': (240, 240, 3), 'batch_size': 32}\n",
      "EfficientNetB2: {'input_shape': (288, 288, 3), 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "### Available Models\n",
    "print(f'Available models: {models_list}')\n",
    "print(f'EfficientNetB0: {model_input_variables[\"EfficientNetB0\"]}')\n",
    "print(f'MobileNetV2: {model_input_variables[\"MobileNetV2\"]}')\n",
    "print(f'MobileNetV3Large: {model_input_variables[\"MobileNetV3Large\"]}')\n",
    "print(f'MobileNetV3Small: {model_input_variables[\"MobileNetV3Small\"]}')\n",
    "print(f'InceptionV3: {model_input_variables[\"InceptionV3\"]}')\n",
    "print(f'EfficientNetB7: {model_input_variables[\"EfficientNetB7\"]}')\n",
    "print(f'EfficientNetB1: {model_input_variables[\"EfficientNetB1\"]}')\n",
    "print(f'EfficientNetB2: {model_input_variables[\"EfficientNetB2\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8ad55-51c9-486b-83dd-5b8cf459fd11",
   "metadata": {},
   "source": [
    "### Chapter 4 Experiments\n",
    "Focus on EfficientNetB0, MobilenetV3Large, MobileNetV2 (comparision), and possibly EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efe05ff6-15ca-49ea-8d55-c1cbff6d4fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time training and validation: 2025-04-09 22:18:03\n",
      "building model: MobileNetV3Small with 2 stage(s)\n",
      "stage1... \n",
      "epochs: 20\n",
      "learning rate of 0.0001\n",
      "trainable: True\n",
      "trainable_layers: None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.layers' has no attribute 'RandomShear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 13\u001b[0m\n\u001b[1;32m      2\u001b[0m models_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model_input_variables\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      3\u001b[0m experiment_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment4: EfficientNetB0 2 stages 20 Epochs all layers lr 1e-5, 5 epochs last 3 trainingable, lr 1 e-7\u001b[39m\u001b[38;5;124m'\u001b[39m: { \n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 13\u001b[0m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_validate_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[33], line 11\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, train_dataset, validate_dataset, num_classes, log_record)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_num \u001b[38;5;129;01min\u001b[39;00m experiments[exper][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_types\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     10\u001b[0m         model_name \u001b[38;5;241m=\u001b[39m models_list[model_num]\n\u001b[0;32m---> 11\u001b[0m         acc, validate_acc, loss, validate_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mlog_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 70\u001b[0m, in \u001b[0;36mrun_model_experiment\u001b[0;34m(experiment_name, model_name, stages, stage1, stage2, train_dataset, validate_dataset, num_classes, log_record)\u001b[0m\n\u001b[1;32m     65\u001b[0m inputs \u001b[38;5;241m=\u001b[39m base_model\u001b[38;5;241m.\u001b[39minput\n\u001b[1;32m     66\u001b[0m rescaled_inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mRescaling(\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)(inputs)  \n\u001b[1;32m     67\u001b[0m augmentation_layers \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[1;32m     68\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomFlip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     69\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomRotation(\u001b[38;5;241m0.1\u001b[39m),\n\u001b[0;32m---> 70\u001b[0m     \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRandomShear\u001b[49m(\u001b[38;5;241m0.2\u001b[39m), \n\u001b[1;32m     71\u001b[0m     layers\u001b[38;5;241m.\u001b[39mRandomTranslation(height_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, width_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m), \n\u001b[1;32m     72\u001b[0m ])\n\u001b[1;32m     73\u001b[0m augmented_inputs \u001b[38;5;241m=\u001b[39m augmentation_layers(rescaled_inputs) \n\u001b[1;32m     74\u001b[0m x \u001b[38;5;241m=\u001b[39m base_model(augmented_inputs) \n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.layers' has no attribute 'RandomShear'"
     ]
    }
   ],
   "source": [
    "#### Experiment 4 EfficentNetB0 \n",
    "models_list = list(model_input_variables.keys())\n",
    "experiment_dict = {\n",
    "    'Experiment4: EfficientNetB0 2 stages 20 Epochs all layers lr 1e-5, 5 epochs last 3 trainingable, lr 1 e-7': { \n",
    "        # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "        'model_types': [2], # EfficientNetB0\n",
    "        'number_of_stages': 2, \n",
    "        'stage1': {'epochs': 20, 'base_trainable': True, 'trainable_layers': None, 'learning_rate': 0.0001},\n",
    "        'stage2': {'epochs': 5, 'base_trainable': False, 'trainable_layers': -3, 'learning_rate': 0.000001}\n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiments(experiment_dict, default_train_dataset, default_validate_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b401ca-b1d1-43b5-9d1b-b6d17125fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for EfficientNetB1\n",
    "EfficientNetB1_train_dataset, EfficientNetB1_validate_dataset = load_images(image_size=(240, 240), batch_size=32)\n",
    "num_classes = len(EfficientNetB1_train_dataset.class_names) # get class count, same no mater how the data is loaded given the same data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833a458-5f95-4f56-864e-6f2429eedf5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Experiment 4 EfficentNetB1 20 Epochs, transfer learning, all layers traininable failed, learing rate 0.0001\n",
    "models_list = list(model_input_variables.keys())\n",
    "experiment_dict = {\n",
    "    'Experiment4: EfficientNetB1 2 stages 10 Epochs top layer, 10 epochs last 3 trainingable, lr 1 e-5': { \n",
    "        # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "        'model_types': [6], # EfficientNetB1\n",
    "        'number_of_stages': 2, \n",
    "        'stage1': {'epochs': 10, 'base_trainable': False, 'trainable_layers': None, 'learning_rate': 0.0001},\n",
    "        'stage2': {'epochs': 10, 'base_trainable': False, 'trainable_layers': -10, 'learning_rate': 0.00001}\n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiments(experiment_dict, EfficientNetB1_train_dataset, EfficientNetB1_validate_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b17ed9-3463-4ccd-8e21-11f56366aa66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Experiment 4 MobileNetV3 large 20 Epochs, transfer learning, all layers traininable, learing rate 0.0001\n",
    "models_list = list(model_input_variables.keys())\n",
    "experiment_dict = {\n",
    "    'Experiment4: MobileNetV3 Large 2 stages 10 Epochs top layer, 10 epochs last 3 trainingable, lr 1 e-5': { \n",
    "        # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "        'model_types': [1], # mobilenetv3large\n",
    "        'number_of_stages': 2, \n",
    "        'stage1': {'epochs': 10, 'base_trainable': False, 'trainable_layers': None, 'learning_rate': 0.0001},\n",
    "        'stage2': {'epochs': 10, 'base_trainable': False, 'trainable_layers': -10, 'learning_rate': 0.00001}   \n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiments(experiment_dict, default_train_dataset, default_validate_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a31de2-24d1-4791-9ffd-9363bdd51acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Experiment 4, MobileNetV2 20 Epochs\n",
    "# added code to stop early and reduce learning rate automatically \n",
    "models_list = list(model_input_variables.keys())\n",
    "experiments_dict = {\n",
    "    'Experiment4: MobileNetV2 2 stages 10 Epochs top layer, 10 epochs last 3 trainingable, lr 1 e-5': { \n",
    "        # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "        'model_types': [0], # mobilenetv2 only\n",
    "                'number_of_stages': 2, \n",
    "        'stage1': {'epochs': 10, 'base_trainable': False, 'trainable_layers': None, 'learning_rate': 0.0001},\n",
    "        'stage2': {'epochs': 10, 'base_trainable': False, 'trainable_layers': -10, 'learning_rate': 0.00001}\n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiments(experiments_dict, default_train_dataset, default_validate_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce338af-efa3-4b0d-92b0-ac425c11d6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585d3b2-e3d4-4013-84ac-c87fe8bb095a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
