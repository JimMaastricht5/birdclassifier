{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a689d0-54b5-4d04-b916-29f36f52746c",
   "metadata": {},
   "source": [
    "### Train Model Experiments NB \n",
    "notes:\n",
    "added tensorboard to try and improve logging.  \n",
    "random shear won't load\n",
    "focus on most accurate approach which was adding softlayer with a higher learning rate\n",
    "gradually tune the layers working backward with a final tuning of all layers\n",
    "saving the best weights and reloading them was failing, since we have early stopping I just saved the full model each epoch\n",
    "flipped model checkpoint back to saving the full model, this may fail again with efficientnet, needs to test at least once\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dae7bf88-623d-49ab-ae35-c883cbe00ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries for training, testing, validation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import imagenet_utils  # will decode predictions out of the model into a 4 dim array of N (image num), imageID, label, probability result[0] would be the set of results for image one\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img  # will load img and reshape, usage is load_img(image_name_loc, target_size=input_shape)\n",
    "from tensorflow.keras.utils import plot_model  # Note: usage syntax is plot_model(instantied_model, to_file='', show_shapes=True)\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import RandomShear  # couldn't get random shear to load\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds  # For loading datasets from GCS\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# add capabilities to generate data and stop early as well as regulation options to avoid over fitting per experiment #1\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "# import all model architectures\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Large, MobileNetV3Small\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "# suppress warnings\n",
    "from absl import logging  # tensorflow internal log\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "tf.get_logger().setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9397c79d-8cba-44fd-b8bc-a367d54bad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary for model config and experiment tracking.... \n",
    "# define global variables\n",
    "gcs_bucket = 'nabirds_filtered'  \n",
    "dataset_path = 'images'  # Relative path within the bucket\n",
    "default_batch_size = 32\n",
    "default_image_size = (224, 224)\n",
    "\n",
    "model_input_variables = {'MobileNetV2': {'input_shape': (224, 224, 3), 'batch_size': 32,},\n",
    "     'MobileNetV3Large': {'input_shape': (224, 224, 3),'batch_size': 32,},\n",
    "    'MobileNetV3Small':{'input_shape': (224, 224, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB0': {'input_shape': (224, 224, 3), 'batch_size': 32,},\n",
    "    'InceptionV3': {'input_shape': (299, 299, 3), 'batch_size': 32,}, # InceptionV3 typically uses 299x299\n",
    "    'EfficientNetB7':{'input_shape': (600, 600, 3), 'batch_size': 16,}, # this is a larger model and the norm seems to be smaller batch sizes for reduced memory use\n",
    "    'EfficientNetB1': {'input_shape': (240, 240, 3), 'batch_size': 32,},  # added 1 thru 6 during experiment 3\n",
    "    'EfficientNetB2': {'input_shape': (288, 288, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB3': {'input_shape': (300, 300, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB4': {'input_shape': (380, 380, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB5': {'input_shape': (456, 456, 3), 'batch_size': 32,},\n",
    "    'EfficientNetB6': {'input_shape': (528, 528, 3), 'batch_size': 32,}\n",
    "}\n",
    "models_list = list(model_input_variables.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c6a513-1aad-4763-a833-c0eae28c78bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_results_to_file(filename, experiment, start_time, end_time, model_name, epochs, \n",
    "                          training_accuracy, validate_accuracy, training_loss, validate_loss,\n",
    "                          num_stages, stage1, stage2):\n",
    "    start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    batch_size = str(model_input_variables[model_name]['batch_size'])\n",
    "    input_shape = str(model_input_variables[model_name]['input_shape']).replace(',','x')\n",
    "    stage1 = f\"stage1 epochs:{stage1['epochs']} trainable: {stage1['base_trainable']} trainable layers: {stage1['trainable_layers']} learning rate: {stage1['learning_rate']}\"\n",
    "    stage2 = f\"stage2 epochs:{stage2['epochs']} trainable: {stage2['base_trainable']} trainable layers: {stage2['trainable_layers']} learning rate: {stage2['learning_rate']}\"\n",
    "    line = f'{experiment},{start_time_str},{end_time_str},{model_name},{batch_size},{epochs},{input_shape},{training_accuracy},' \\\n",
    "           f'{validate_accuracy},{training_loss},{validate_loss},{num_stages},{stage1},{stage2}\\n'\n",
    "    if not os.path.exists(filename):      # Check if the file exists, and add a header if it's new\n",
    "        header = 'experiment,start_time,end_time,model_name,batch_size,epochs,input_shape,training_accuracy,validate_accuracy,training_loss,validate_loss,num_stages,stage1,stage2\\n'\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(header + line)\n",
    "    else:\n",
    "        with open(filename, \"a\") as f: # append to existing file\n",
    "            f.write(line)\n",
    "    print(f'experiment tracking updated')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293b3f33-f2f5-4147-a979-ee49b8c50341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images_gcs(bucket_name, dataset_path, model_image_size, model_batch_size):\n",
    "    dataset = None\n",
    "    gcs_dataset_path = f\"gs://{bucket_name}/{dataset_path}\"\n",
    "    try:\n",
    "        dataset = keras.utils.image_dataset_from_directory(gcs_dataset_path, image_size=model_image_size,\n",
    "            batch_size=model_batch_size, label_mode='categorical',)  # categorical is for softmax layer\n",
    "    except Exception as e:\n",
    "        print(f'error loading dataset from gcs: {e}')    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3637ff1b-af98-4d1b-ab03-5fcf0051e528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into its own cell so we do not have to repeat this long operation, takes 10 minutes....\n",
    "# need to run this each time for different image and batch sizes\n",
    "def load_images(image_size=default_image_size, batch_size=default_batch_size):\n",
    "    start_time = time.time()\n",
    "    start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "    print(f'Start loading images time: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'Loading with image size of {image_size} and batch size of {batch_size}')\n",
    "\n",
    "    train_dataset = load_images_gcs(gcs_bucket, os.path.join(dataset_path, 'train'), image_size, batch_size)\n",
    "    validate_dataset = load_images_gcs(gcs_bucket, os.path.join(dataset_path, 'test'), image_size, batch_size)\n",
    "\n",
    "    if train_dataset is None or validate_dataset is None:\n",
    "        print(f'dataset loading failed.')\n",
    "    return train_dataset, validate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89bccfe4-decc-4edf-9120-e82ccfe42360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_results(acc, validate_acc, loss, validate_loss):\n",
    "    epochs_plt = range(1, len(acc) + 1)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_plt, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs_plt, validate_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_plt, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs_plt, validate_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bc17b88-aae1-4546-8266-c7618ad6ebe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lock and unlock layers, make this bullet proof so I don't have to think about the experiments too much\n",
    "def lock_unlock_layers(model, train_last_x_layers):\n",
    "    train_last_x_layers = 0 if train_last_x_layers == None else train_last_x_layers\n",
    "    fine_tune_at = len(model.layers) - abs(train_last_x_layers)                        \n",
    "    fine_tune_at = 0 if fine_tune_at < 0 else fine_tune_at\n",
    "    for layer in model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[fine_tune_at:]:\n",
    "        layer.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8cfa5d68-42f8-4a13-947d-160b04046aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.autograph.experimental.do_not_convert\n",
    "def run_model_experiment(experiment_name, model_name, stages, stage1, stage2, train_dataset, validate_dataset, num_classes, log_record):\n",
    "    stage1_learning = stage1[\"learning_rate\"]\n",
    "    stage1_epochs = stage1[\"epochs\"]\n",
    "    stage1_base_trainable = stage1['base_trainable']\n",
    "    stage1_trainable_layers = stage1['trainable_layers']\n",
    "    stage2_learning = stage2[\"learning_rate\"]\n",
    "    stage2_epochs = stage2[\"epochs\"]\n",
    "    stage2_base_trainable = stage2['base_trainable']\n",
    "    stage2_trainable_layers = stage2['trainable_layers']\n",
    "    \n",
    "    start_time = time.time()\n",
    "    start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "    print(f'Start time training and validation: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    print(f'building model: {model_name} with {stages} stage(s)')\n",
    "    print(f'stage1... ')\n",
    "    print(f'epochs: {stage1_epochs}')\n",
    "    print(f'learning rate of {stage1_learning}')\n",
    "    print(f'trainable: {stage1_base_trainable}')\n",
    "    print(f'trainable_layers: {stage1_trainable_layers}')\n",
    "    \n",
    "     # load each mode type and modify head for softmax replacement\n",
    "    if model_name == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "    elif model_name == 'MobileNetV3Large':\n",
    "        base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "    elif model_name == 'MobileNetV3Small':\n",
    "        base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) \n",
    "    elif model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    elif model_name == 'InceptionV3':\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(229, 229, 3))\n",
    "    elif model_name == 'EfficientNetB7':\n",
    "        base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(600, 600, 3))\n",
    "    elif model_name == 'EfficientNetB1':\n",
    "        base_model = EfficientNetB1(weights='imagenet', include_top=False, input_shape=(240, 240, 3))\n",
    "    elif model_name == 'EfficientNetB2':\n",
    "        base_model = EfficientNetB2(weights='imagenet', include_top=False, input_shape=(288, 288, 3))\n",
    "    elif model_name == 'EfficientNetB3':\n",
    "        base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "    else:\n",
    "        print(f'unknown model {model_name} inf run_model_experiment case statement')\n",
    "\n",
    "    ### setup call backs and other admin...\n",
    "    # save best model, save model when monitored metric improved, 'max' for accuracy, 'min' for loss\n",
    "    # callbacks early stopping and learning rate reduction\n",
    "    # suppress warnings\n",
    "    model_filename = experiment_name + model_name + '.h5'\n",
    "    # model_checkpoint_callback = ModelCheckpoint(filepath=model_filename, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1)  # added save weights for efficientnet\n",
    "    # model_checkpoint_callback = ModelCheckpoint(filepath=model_filename, save_best_only=True, monitor='val_accuracy', mode='max', verbose=1, save_weights_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001)\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    \n",
    "    #####  setup stage 1 of X #####\n",
    "    base_model.trainable = stage1_base_trainable  # true unlocks the entire model\n",
    "    if stage1_base_trainable is False and stage1_trainable_layers != None:  # false a number unlocks the last x layers\n",
    "        base_model = lock_unlock_layers(model=base_model, train_last_x_layers=stage1_trainable_layers)\n",
    "    x = base_model.output  # start adding custom layers\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)  \n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # create the model with rescaling layer, this will automatically normalize the images within the model, bulletproofs feeder code\n",
    "    # normalize pixel values to [0, 1], not sure if this was done in the old mobilenetv2 model\n",
    "    inputs = base_model.input\n",
    "    rescaled_inputs = tf.keras.layers.Rescaling(1./255)(inputs)  \n",
    "    augmentation_layers = Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        # layers.RandomShear(0.2), # failed to load\n",
    "        layers.RandomTranslation(height_factor=0.1, width_factor=0.1), \n",
    "    ])\n",
    "    augmented_inputs = augmentation_layers(rescaled_inputs) \n",
    "    x = base_model(augmented_inputs) \n",
    "    model = Model(inputs=inputs, outputs=predictions) # use original inputs\n",
    "    \n",
    "    # Define TensorBoard callback\n",
    "    log_dir = os.path.join(\"logs\", experiment_name + \"_\" + model_name + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        \n",
    "    # compile and train model, epoch zero is starting place for first stage, categorical crossentropy is for multi-class classification\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=stage1_learning), loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "    history_phase1 = model.fit(train_dataset, epochs=stage1_epochs, initial_epoch=0, validation_data=validate_dataset, \n",
    "                               callbacks=[model_checkpoint_callback, early_stopping, reduce_lr] )  \n",
    "                               # callbacks=[model_checkpoint_callback, early_stopping, reduce_lr] )  # removed model checkpoint as it was not working propertly\n",
    "\n",
    "    ##### setup stage 2 if requested\n",
    "    combined_history = {}\n",
    "    print(f'history 1 keys: {history_phase1.history.keys()}')\n",
    "    if stages == 2:\n",
    "        print(f'stage2...')\n",
    "        model = lock_unlock_layers(model=model, train_last_x_layers=stage2_trainable_layers)\n",
    "        # Recompile the model and continue from phase1, last epoch + 1 to move to next available \n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=stage2_learning), loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "        history_phase2 = model.fit(train_dataset, epochs=stage1_epochs + stage2_epochs, initial_epoch=stage1_epochs, validation_data=validate_dataset,\n",
    "                                  callbacks=[model_checkpoint_callback, early_stopping, reduce_lr])   \n",
    "        print(f'history2 keys: {history_phase2.history.keys()}')\n",
    "        for key in history_phase1.history:  # combine history\n",
    "            try:\n",
    "                combined_history[key] = history_phase1.history[key] + history_phase2.history[key]\n",
    "            except:\n",
    "                pass\n",
    "                #     print(f'history1 key {key} not found in history2 ')\n",
    "        for key2 in history_phase2.history:\n",
    "            if key2 not in history_phase1.history:\n",
    "                combined_history[key2] = history_phase2.history[key2]\n",
    "    else:\n",
    "        stage2_epochs=0\n",
    "        combined_history = history_phase1.history  # if one state take stage 1 hist    \n",
    "                \n",
    "    #### process results and save model\n",
    "    # save the entire model (architecture + weights)\n",
    "    try:\n",
    "        model.save(model_filename)\n",
    "        print(f'model saved to: {model_filename}')\n",
    "    except Exception as e:\n",
    "        print(f'model save failed with error {e}')\n",
    "    \n",
    "    # record training time\n",
    "    end_time = time.time()\n",
    "    end_time_datetime = datetime.datetime.fromtimestamp(end_time)\n",
    "    print(f'End time training and validation: {end_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "    # write_results_to_file\n",
    "    total_epochs = stage1_epochs + stage2_epochs\n",
    "    acc = combined_history['accuracy']\n",
    "    validate_acc = combined_history['val_accuracy']\n",
    "    loss = combined_history['loss']\n",
    "    validate_loss = combined_history['val_loss']\n",
    "\n",
    "    if log_record:\n",
    "        write_results_to_file('experiment_log.csv', experiment_name, start_time_datetime, end_time_datetime, model_name, total_epochs, \n",
    "                              acc[-1], validate_acc[-1], loss[-1], validate_loss[-1], stages, stage1, stage2)\n",
    "    plot_training_results(acc, validate_acc, loss, validate_loss) \n",
    "    return acc, validate_acc, loss, validate_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3501839b-a05c-423e-971e-d759809acdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc7d276b-dcc1-4589-b863-3bb9e84946f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the experiments dictionary drives the model types and training parameters \n",
    "# loop over each model type, stages, and write out results of experiment to a file, save the model\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def run_experiments(experiments, train_dataset, validate_dataset, num_classes, log_record=True):\n",
    "    for exper in list(experiments.keys()):\n",
    "        stages = experiments[exper]['number_of_stages']\n",
    "        stage1 = experiments[exper]['stage1']\n",
    "        stage2 = experiments[exper]['stage2']\n",
    "        \n",
    "        for model_num in experiments[exper]['model_types']:\n",
    "            model_name = models_list[model_num]\n",
    "            acc, validate_acc, loss, validate_loss = run_model_experiment(exper, model_name, stages, stage1, stage2, \n",
    "                                                                          train_dataset, validate_dataset, num_classes, \n",
    "                                                                         log_record)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c96d76ca-7817-4ca6-9186-e869b6e9d293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading images time: 2025-04-12 14:03:41\n",
      "Loading with image size of (224, 224) and batch size of 32\n",
      "Found 2455 files belonging to 27 classes.\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f22978ed120> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.string, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.string, name=None),)] [kwargs: {}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f22978eea70> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.int32, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.int32, name=None),)] [kwargs: {}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 14:09:58.746089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.071803: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.072092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.075699: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-12 14:09:59.078216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.078507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.078680: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.325584: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.326708: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.326912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-04-12 14:09:59.327785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6993 MB memory:  -> device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 files belonging to 27 classes.\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f22978eea70> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.string, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.string, name=None),)] [kwargs: {}]\n",
      "Level 1:tensorflow:Creating new FuncGraph for Python function <function StructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn at 0x7f22978ee9e0> (key: FunctionCacheKey(function_type=FunctionType(parameters=[Parameter(name=args_kwargs, kindPOSITIONAL_ONLY, optional=False, type_constraint=Tuple(components=(Tuple(components=(TensorSpec(shape=(), dtype=tf.int32, name=None),)), Dict(mapping={}))))], captures=OrderedDict()), call_context=FunctionContext(context=EagerContext(parent_graph=None, device_functions=(), colocation_stack=(), in_cross_replica_context=False, variable_policy=None, xla_context_id=0))))\n",
      "Level 2:tensorflow:Python function signature [args: (TensorSpec(shape=(), dtype=tf.int32, name=None),)] [kwargs: {}]\n"
     ]
    }
   ],
   "source": [
    "# load the default data 224x224x3 ,batch size 32 data set.  do not loop over this code unless its an exception. \n",
    "# takes about 10 minutes, note this will output warning/errors since this NB is not using a GPU\n",
    "# request a different load for a different model size, copy and paste code and change parameters\n",
    "default_train_dataset, default_validate_dataset = load_images()\n",
    "num_classes = len(default_train_dataset.class_names) # get class count, same no mater how the data is loaded given the same data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d90a34f-90d0-40c1-9a77-8a32b37ddbeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Experiments\n",
    "quick primer:  \n",
    "Accuracy: overall proportion of correct predictions (both true positives and true negatives) out of all predictions made.\n",
    "Formula: (True Positives + True Negatives) / (Total Predictions)\n",
    "Precision: measures the proportion of true positive predictions out of all positive predictions made by the model.\n",
    "Formula: True Positives / (True Positives + False Positives)\n",
    "Recall (also known as Sensitivity): measures the proportion of actual positive instances that the model correctly identified.\n",
    "Formula: True Positives / (True Positives + False Negatives)\n",
    "\n",
    "- Early experiment: learning_rate to low resulted in overfitting .001 with 50 epochs.  Added code to save best model since the results detoritated as more epochs were applied.  added libraries to generate more images if needed and for early stopping and learning rate reduction.  not in code yet \n",
    "- Experiment1: lowered learning rate to .0001 and trained for 25 epochs.  much better result.\n",
    "- Experiment2: incorporated early stopping code and learning rate reduction and increased epochs to 50.  future: add regulaziation and drop out layers? add more training images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1025d43-4a0f-4b7d-acd8-6a700105079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models: ['MobileNetV2', 'MobileNetV3Large', 'MobileNetV3Small', 'EfficientNetB0', 'InceptionV3', 'EfficientNetB7', 'EfficientNetB1', 'EfficientNetB2', 'EfficientNetB3', 'EfficientNetB4', 'EfficientNetB5', 'EfficientNetB6']\n",
      "EfficientNetB0: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "MobileNetV2: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "MobileNetV3Large: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "MobileNetV3Small: {'input_shape': (224, 224, 3), 'batch_size': 32}\n",
      "InceptionV3: {'input_shape': (299, 299, 3), 'batch_size': 32}\n",
      "EfficientNetB7: {'input_shape': (600, 600, 3), 'batch_size': 16}\n",
      "EfficientNetB1: {'input_shape': (240, 240, 3), 'batch_size': 32}\n",
      "EfficientNetB2: {'input_shape': (288, 288, 3), 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "### Available Models\n",
    "print(f'Available models: {models_list}')\n",
    "print(f'EfficientNetB0: {model_input_variables[\"EfficientNetB0\"]}')\n",
    "print(f'MobileNetV2: {model_input_variables[\"MobileNetV2\"]}')\n",
    "print(f'MobileNetV3Large: {model_input_variables[\"MobileNetV3Large\"]}')\n",
    "print(f'MobileNetV3Small: {model_input_variables[\"MobileNetV3Small\"]}')\n",
    "print(f'InceptionV3: {model_input_variables[\"InceptionV3\"]}')\n",
    "print(f'EfficientNetB7: {model_input_variables[\"EfficientNetB7\"]}')\n",
    "print(f'EfficientNetB1: {model_input_variables[\"EfficientNetB1\"]}')\n",
    "print(f'EfficientNetB2: {model_input_variables[\"EfficientNetB2\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d8ad55-51c9-486b-83dd-5b8cf459fd11",
   "metadata": {},
   "source": [
    "### Chapter 4 Experiments\n",
    "Focus on EfficientNetB0, MobilenetV3Large, MobileNetV2 (comparision), and possibly EfficientNetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efe05ff6-15ca-49ea-8d55-c1cbff6d4fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time training and validation: 2025-04-12 14:53:39\n",
      "building model: EfficientNetB0 with 2 stage(s)\n",
      "stage1... \n",
      "epochs: 4\n",
      "learning rate of 0.001\n",
      "trainable: False\n",
      "trainable_layers: -3\n",
      "WARNING: AutoGraph could not transform <function _convert_function_call.<locals>.f at 0x7f1f90339c60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('converter', 'func'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _convert_function_call.<locals>.f at 0x7f22a09ff0a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('converter', 'func'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "Epoch 1/4\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f1f44131240> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_train_function.<locals>.train_function at 0x7f1f44131240>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 14:53:48.334646: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_4/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - ETA: 0s - loss: 0.8743 - accuracy: 0.7462 - precision_5: 0.8957 - recall_5: 0.6436WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f1ed4754700> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function Model.make_test_function.<locals>.test_function at 0x7f1ed4754700>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.83736, saving model to Experiment4: EfficientNetB0: Chapter 4 TuningEfficientNetB0.h5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m models_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model_input_variables\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      6\u001b[0m experiment_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperiment4: EfficientNetB0: Chapter 4 Tuning\u001b[39m\u001b[38;5;124m'\u001b[39m: { \n\u001b[1;32m      8\u001b[0m         \u001b[38;5;66;03m# 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 16\u001b[0m \u001b[43mrun_experiments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_validate_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:642\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[28], line 12\u001b[0m, in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, train_dataset, validate_dataset, num_classes, log_record)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m model_num \u001b[38;5;129;01min\u001b[39;00m experiments[exper][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_types\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     11\u001b[0m         model_name \u001b[38;5;241m=\u001b[39m models_list[model_num]\n\u001b[0;32m---> 12\u001b[0m         acc, validate_acc, loss, validate_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                                                      \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                                                                     \u001b[49m\u001b[43mlog_record\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:642\u001b[0m, in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 642\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mDISABLED):\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[27], line 85\u001b[0m, in \u001b[0;36mrun_model_experiment\u001b[0;34m(experiment_name, model_name, stages, stage1, stage2, train_dataset, validate_dataset, num_classes, log_record)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# compile and train model, epoch zero is starting place for first stage, categorical crossentropy is for multi-class classification\u001b[39;00m\n\u001b[1;32m     83\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mstage1_learning), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     84\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mPrecision(), tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mRecall()])\n\u001b[0;32m---> 85\u001b[0m history_phase1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage1_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m##### setup stage 2 if requested\u001b[39;00m\n\u001b[1;32m     89\u001b[0m combined_history \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/json/__init__.py:238\u001b[0m, in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONEncoder\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/json/encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[0;32m/opt/conda/envs/tensorflow/lib/python3.10/json/encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[1;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>."
     ]
    }
   ],
   "source": [
    "#### Experiment 4 EfficentNetB0 \n",
    "# added 3 layers to model, train added layers in first stage, first stage platued at 4 epochs at 90.0% validation accuracy, 1e-3\n",
    "# allow for deeper retaining in stage 2, 1e-5\n",
    "# add stage 3 for full fine tuning ??\n",
    "models_list = list(model_input_variables.keys())\n",
    "experiment_dict = {\n",
    "    'Experiment4: EfficientNetB0: Chapter 4 Tuning': { \n",
    "        # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "        'model_types': [3], # EfficientNetB0\n",
    "        'number_of_stages': 2, \n",
    "        'stage1': {'epochs': 4, 'base_trainable': False, 'trainable_layers': -3, 'learning_rate': 0.001},\n",
    "        'stage2': {'epochs': 50, 'base_trainable': False, 'trainable_layers': -10, 'learning_rate': 0.00001}\n",
    "    }\n",
    "}\n",
    "\n",
    "run_experiments(experiment_dict, default_train_dataset, default_validate_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b401ca-b1d1-43b5-9d1b-b6d17125fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data for EfficientNetB1\n",
    "# EfficientNetB1_train_dataset, EfficientNetB1_validate_dataset = load_images(image_size=(240, 240), batch_size=32)\n",
    "# num_classes = len(EfficientNetB1_train_dataset.class_names) # get class count, same no mater how the data is loaded given the same data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b17ed9-3463-4ccd-8e21-11f56366aa66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #### Experiment 4 MobileNetV3 large 20 Epochs, transfer learning, all layers traininable, learing rate 0.0001\n",
    "# models_list = list(model_input_variables.keys())\n",
    "# experiment_dict = {\n",
    "#     'Experiment4: MobileNetV3 Large 2 stages 10 Epochs top layer, 10 epochs last 3 trainingable, lr 1 e-5': { \n",
    "#         # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "#         'model_types': [1], # mobilenetv3large\n",
    "#         'number_of_stages': 2, \n",
    "#         'stage1': {'epochs': 10, 'base_trainable': False, 'trainable_layers': None, 'learning_rate': 0.0001},\n",
    "#         'stage2': {'epochs': 10, 'base_trainable': False, 'trainable_layers': -10, 'learning_rate': 0.00001}   \n",
    "#     }\n",
    "# }\n",
    "\n",
    "# run_experiments(experiment_dict, default_train_dataset, default_validate_dataset, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a31de2-24d1-4791-9ffd-9363bdd51acf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Experiment 4, MobileNetV2 20 Epochs\n",
    "# added code to stop early and reduce learning rate automatically \n",
    "# models_list = list(model_input_variables.keys())\n",
    "# experiments_dict = {\n",
    "#     'Experiment4: MobileNetV2 2 stages 10 Epochs top layer, 10 epochs last 3 trainingable, lr 1 e-5': { \n",
    "#         # 'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "#         'model_types': [0], # mobilenetv2 only\n",
    "#                 'number_of_stages': 2, \n",
    "#         'stage1': {'epochs': 10, 'base_trainable': False, 'trainable_layers': None, 'learning_rate': 0.0001},\n",
    "#         'stage2': {'epochs': 10, 'base_trainable': False, 'trainable_layers': -10, 'learning_rate': 0.00001}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# run_experiments(experiments_dict, default_train_dataset, default_validate_dataset, num_classes)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
