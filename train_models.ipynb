{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a689d0-54b5-4d04-b916-29f36f52746c",
   "metadata": {},
   "source": [
    "### Tensor Flow 2-11 notebook\n",
    "\n",
    "Notes: \n",
    "- Notebook should be running with an Nvidia GPU to for top performance\n",
    "- load_img will load a nparray with x, y, 3 color dims.  \n",
    "- If we're just processing one image we will need to np.expand_dims(image, axies=0) to get 1, x, y, 3. The library expects N images in the first dim\n",
    "- should set random seed on tf.random.set_seed(1) for reproduceability \n",
    "- \n",
    "\n",
    "last change 3/6/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae7bf88-623d-49ab-ae35-c883cbe00ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries for training, testing, validation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import imagenet_utils  # will decode predictions out of the model into a 4 dim array of N (image num), imageID, label, probability result[0] would be the set of results for image one\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img  # will load img and reshape, usage is load_img(image_name_loc, target_size=input_shape)\n",
    "from tensorflow.keras.utils import plot_model  # Note: usage syntax is plot_model(instantied_model, to_file='', show_shapes=True)\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds  # For loading datasets from GCS\n",
    "\n",
    "# import all model architectures\n",
    "from tensorflow.keras.applications import MobileNetV2, MobileNetV3Large, MobileNetV3Small\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB7\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9397c79d-8cba-44fd-b8bc-a367d54bad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary for model config and experiment tracking.... \n",
    "model_input_variables = {\n",
    "    \"EfficientNetB0\": {\n",
    "        \"input_shape\": (224, 224, 3),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"MobileNetV2\": {\n",
    "        \"input_shape\": (224, 224, 3),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "     \"MobileNetV3Large\": { #MobileNetV3 Large will be used to compare accuracy loss with small, prob not a candidate for rasp pi running\n",
    "        \"input_shape\": (224, 224, 3),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"MobileNetV3Small\":{ \n",
    "        \"input_shape\": (224, 224, 3),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"InceptionV3\": {\n",
    "        \"input_shape\": (299, 299, 3),  # InceptionV3 typically uses 299x299\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"EfficientNetB7\":{\n",
    "        \"input_shape\": (600, 600, 3),  # big values!\n",
    "        \"batch_size\": 16, # this is a larger model and the norm seems to be smaller batch sizes for reduced memory use\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f'EfficientNetB0: {model_input_variables[\"EfficientNetB0\"]}')\n",
    "print(f'MobileNetV2: {model_input_variables[\"MobileNetV2\"]}')\n",
    "print(f'MobileNetV3Large: {model_input_variables[\"MobileNetV3Large\"]}')\n",
    "print(f'MobileNetV3Small: {model_input_variables[\"MobileNetV3Small\"]}')\n",
    "print(f'InceptionV3: {model_input_variables[\"InceptionV3\"]}')\n",
    "print(f'EfficientNetB7: {model_input_variables[\"EfficientNetB7\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb609827-b297-450f-bc1e-07ebaaf90a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Experiment Configuration and globals\n",
    "gcs_bucket = 'nabirds_filtered'  \n",
    "dataset_path = 'images'  # Relative path within the bucket\n",
    "default_batch_size = 32\n",
    "default_image_size = (224, 224)\n",
    "\n",
    "# experiment, make sure to increment the number\n",
    "models_list = ['EfficientNetB0', 'MobileNetV2', 'MobileNetV3Large', 'MobileNetV3Small', 'InceptionV3', 'EfficientNetB7']\n",
    "run_experiments = {\n",
    "    'experiment_number': 1, \n",
    "    'model_types': [0, 1, 2, 3], # leave out the two models with weird image sizes for now\n",
    "    'number_of_stages': 1, \n",
    "    'stage1': {'epochs': 5, 'trainable': False, 'trainable_layers': None},\n",
    "    'stage2': {'epochs': 2, 'trainable': True, 'trainable_layers': -2}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6a513-1aad-4763-a833-c0eae28c78bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_results_to_file(filename, start_time, end_time, model_name, batch_size, epochs, \n",
    "                          input_shape, training_accuracy, validate_accuracy, training_loss, validate_loss):\n",
    "    start_time_str = start_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    end_time_str = end_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    line = f'{start_time_str},{end_time_str},{model_name},{batch_size},{epochs},{input_shape},{training_accuracy},' \\\n",
    "           f'{validate_accuracy},{training_loss},{validate_loss}\\n'\n",
    "    if not os.path.exists(filename):      # Check if the file exists, and add a header if it's new\n",
    "        header = 'start_time,end_time,model_name,batch_size,epochs,input_shape,training_accuracy,validate_accuracy,training_loss,validate_loss\\n'\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(header + line)\n",
    "    else:\n",
    "        with open(filename, \"a\") as f: # or append to existing file\n",
    "            f.write(line)\n",
    "    print(f'experiment tracking updated')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293b3f33-f2f5-4147-a979-ee49b8c50341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_gcs_dataset(bucket_name, dataset_path, model_image_size, model_batch_size):\n",
    "    dataset = None\n",
    "    gcs_dataset_path = f\"gs://{bucket_name}/{dataset_path}\"\n",
    "    try:\n",
    "        dataset = keras.utils.image_dataset_from_directory(gcs_dataset_path, image_size=model_image_size,\n",
    "            batch_size=model_batch_size, label_mode='categorical',)  # categorical is for softmax layer\n",
    "    except Exception as e:\n",
    "        print(f'error loading dataset from gcs: {e}')    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3637ff1b-af98-4d1b-ab03-5fcf0051e528",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# split into its own cell so we do not have to repeat this long operation, takes 10 minutes....\n",
    "start_time = time.time()\n",
    "start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "print(f'Start time: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# need to load this each time for different batch and image size, load default of 224x224 with batch_size of 32\n",
    "default_train_dataset = load_gcs_dataset(gcs_bucket, os.path.join(dataset_path, 'train'), default_image_size, default_batch_size)\n",
    "default_validate_dataset = load_gcs_dataset(gcs_bucket, os.path.join(dataset_path, 'test'), default_image_size, default_batch_size)\n",
    "\n",
    "if default_train_dataset is None or default_validate_dataset is None:\n",
    "    print(f'dataset loading failed.')\n",
    "    \n",
    "num_classes = len(default_train_dataset.class_names) # get class count, same no mater how the data is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a39f7-d768-4c14-9aaa-3af0ad9e94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the experiments dictionary to train the models\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "print(f'Start time: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# load model and modify head\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # unlock top layer for softmax replacement\n",
    "base_model.trainable = True  # Unlock the base model, note this should be changed to freeze some layers per lit review ??\n",
    "\n",
    "# add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Optional: Add more dense layers\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# create the model with rescaling layer, this will automatically normalize the images within the model, bulletproofs feeder code\n",
    "inputs = base_model.input\n",
    "rescaled_inputs = tf.keras.layers.Rescaling(1./255)(inputs)  # normalize pixel values to [0, 1], not sure if this was done in the old mobilenetv2 model\n",
    "x = base_model(rescaled_inputs) # pass the rescaled input through the base model\n",
    "model = Model(inputs=inputs, outputs=predictions) # use the original inputs, this is weird, but how it was done in tutorial...\n",
    "\n",
    "# compile and train model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',  # Important for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(default_train_dataset, epochs=epochs, initial_epoch=0, validation_data=default_validate_dataset)  # initial epoch=0 is traing from scratch\n",
    "\n",
    "model.save('mobilenet_retrained.h5')  # save the model\n",
    "\n",
    "# plot results, none error here means model did not train\n",
    "acc = history.history['accuracy']\n",
    "validate_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "validate_loss = history.history['val_loss']\n",
    "\n",
    "epochs_plt = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_plt, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs_plt, validate_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_plt, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs_plt, validate_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# record training time\n",
    "end_time = time.time()\n",
    "end_time_datetime = datetime.datetime.fromtimestamp(end_time)\n",
    "print(f'End time: {end_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8a55a3-dd11-4a2a-8dd7-6cb40a14d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample predictions\n",
    "# small_img = image.load_img(img_path, target_size=(224, 224))\n",
    "# small_img_array = image.img_to_array(small_img)\n",
    "# small_img_array = np.expand_dims(small_img_array, axis=0)\n",
    "# small_img_array = preprocess_input(small_img_array)\n",
    "# small_predictions = model_small.predict(small_img_array)\n",
    "# decoded_small_predictions = decode_predictions(small_predictions, top=1)[0]\n",
    "# print(decoded_small_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc7a55-0040-47f3-b22a-100b5d58cbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### old dead code.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453cfdb-4d73-4586-96d5-50c32cb16cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_SIZE = (224, 224)\n",
    "# BATCH_SIZE = 32\n",
    "# train_dataset = load_gcs_dataset(GCS_BUCKET, os.path.join(DATASET_PATH, 'train'), IMAGE_SIZE, BATCH_SIZE)\n",
    "# validation_dataset = load_gcs_dataset(GCS_BUCKET, os.path.join(DATASET_PATH, 'test'), IMAGE_SIZE, BATCH_SIZE)\n",
    "\n",
    "# if train_dataset is None or validation_dataset is None:\n",
    "#     print(\"Dataset loading failed. Exiting.\")\n",
    "#     exit()\n",
    "\n",
    "# NUM_CLASSES = len(train_dataset.class_names) # Get class count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23f9e8-b7a4-4c5a-801d-e1012615e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Code for MobilenetV2\n",
    "##### MobileNetV2 training sample, use for comparision to old model in feeder\n",
    "# start_time = time.time()\n",
    "# start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "# print(f'Start time: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "# ###### load mobilenetv2 and modify head\n",
    "# base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # unlock top layer for softmax replacement\n",
    "# base_model.trainable = True  # Unlock the base model, note this should be changed to freeze some layers per lit review ??\n",
    "\n",
    "# # add custom layers\n",
    "# x = base_model.output\n",
    "# x = GlobalAveragePooling2D()(x)\n",
    "# x = Dense(1024, activation='relu')(x)  # Optional: Add more dense layers\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# # create the model with Rescaling layer\n",
    "# inputs = base_model.input\n",
    "# rescaled_inputs = tf.keras.layers.Rescaling(1./255)(inputs)  # normalize pixel values to [0, 1], not sure if this was done in the old mobilenetv2 model\n",
    "# x = base_model(rescaled_inputs) # pass the rescaled input through the base model\n",
    "# model = Model(inputs=inputs, outputs=predictions) # use the original inputs, this is weird, but how it was done in tutorial...\n",
    "\n",
    "# # compile model\n",
    "# model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "#               loss='categorical_crossentropy',  # Important for multi-class classification\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # train the model\n",
    "# history = model.fit(train_dataset, epochs=epochs, initial_epoch=0, validation_data=validation_dataset)  # initial epoch=0 is traing from scratch\n",
    "\n",
    "# # save model\n",
    "# model.save('mobilenet_retrained.h5')\n",
    "\n",
    "# # plot results, error here means model did not train\n",
    "# acc = history.history['accuracy']\n",
    "# test_acc = history.history['val_accuracy']\n",
    "# loss = history.history['loss']\n",
    "# test_loss = history.history['val_loss']\n",
    "\n",
    "# epochs_plt = range(1, len(acc) + 1)\n",
    "# plt.figure(figsize=(12, 5))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_plt, acc, 'b', label='Training accuracy')\n",
    "# plt.plot(epochs_plt, test_acc, 'r', label='Test accuracy')\n",
    "# plt.title('Training and Testing Accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_plt, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs_plt, test_loss, 'r', label='Test loss')\n",
    "# plt.title('Training and Test Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # record training time\n",
    "# end_time = time.time()\n",
    "# end_time_datetime = datetime.datetime.fromtimestamp(end_time)\n",
    "# print(f'End time: {end_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b860be-a547-41d1-8db1-c51d4231f316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
