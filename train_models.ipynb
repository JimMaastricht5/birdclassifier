{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a689d0-54b5-4d04-b916-29f36f52746c",
   "metadata": {},
   "source": [
    "### Tensor Flow 2-11 notebook\n",
    "\n",
    "Notes: \n",
    "- Notebook should be running with an Nvidia GPU to for top performance\n",
    "- load_img will load a nparray with x, y, 3 color dims.  \n",
    "- If we're just processing one image we will need to np.expand_dims(image, axies=0) to get 1, x, y, 3. The library expects N images in the first dim\n",
    "- should set random seed on tf.random.set_seed(1) for reproduceability \n",
    "- \n",
    "\n",
    "last change 3/6/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae7bf88-623d-49ab-ae35-c883cbe00ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 13:05:01.055102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-08 13:05:04.138005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-03-08 13:05:04.138244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-03-08 13:05:04.138259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# import the libraries for training, testing, validation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import imagenet_utils  # will decode predictions out of the model into a 4 dim array of N (image num), imageID, label, probability result[0] would be the set of results for image one\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img  # will load img and reshape, usage is load_img(image_name_loc, target_size=input_shape)\n",
    "from tensorflow.keras.utils import plot_model  # Note: usage syntax is plot_model(instantied_model, to_file='', show_shapes=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds  # For loading datasets from GCS\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9397c79d-8cba-44fd-b8bc-a367d54bad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training packages\n",
    "# import the necessary packages\n",
    "# from tensorflow import reduce_mean\n",
    "# from tensorflow.keras import Model\n",
    "# from tensorflow.keras import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D\n",
    "# from tensorflow.keras.layers import InputLayer\n",
    "# from tensorflow.keras.layers import Conv2DTranspose\n",
    "# from tensorflow.keras.losses import Reduction\n",
    "# from tensorflow.keras.losses import MeanSquaredError\n",
    "# from tensorflow.image import convert_image_dtype\n",
    "# from tensorflow.keras.preprocessing.image import array_to_img\n",
    "\n",
    "# import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb609827-b297-450f-bc1e-07ebaaf90a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "GCS_BUCKET = 'nabirds_filtered'  \n",
    "DATASET_PATH = 'images'  # Relative path within the bucket\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = None  # Will be determined from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293b3f33-f2f5-4147-a979-ee49b8c50341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_gcs_dataset(bucket_name, dataset_path, image_size, batch_size):\n",
    "    \"\"\"Loads a dataset from Google Cloud Storage.\"\"\"\n",
    "\n",
    "    gcs_dataset_path = f\"gs://{bucket_name}/{dataset_path}\"\n",
    "\n",
    "    try:\n",
    "        # Attempt to load the dataset using tf.keras.utils.image_dataset_from_directory.\n",
    "        # This handles directory structures well.\n",
    "\n",
    "        dataset = keras.utils.image_dataset_from_directory(\n",
    "            gcs_dataset_path,\n",
    "            image_size=image_size,\n",
    "            batch_size=batch_size,\n",
    "            label_mode='categorical', # important for softmax\n",
    "        )\n",
    "        return dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset from GCS: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3637ff1b-af98-4d1b-ab03-5fcf0051e528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading dataset from GCS: Could not find directory gs://nabirds_filtered/images/train\n",
      "Error loading dataset from GCS: Could not find directory gs://nabirds_filtered/images/validation\n",
      "Dataset loading failed. Exiting.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset loading failed. Exiting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     exit()\n\u001b[0;32m----> 8\u001b[0m NUM_CLASSES \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_names\u001b[49m) \u001b[38;5;66;03m# Get class count.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "train_dataset = load_gcs_dataset(GCS_BUCKET, os.path.join(DATASET_PATH, 'train'), IMAGE_SIZE, BATCH_SIZE)\n",
    "validation_dataset = load_gcs_dataset(GCS_BUCKET, os.path.join(DATASET_PATH, 'validation'), IMAGE_SIZE, BATCH_SIZE)\n",
    "\n",
    "if train_dataset is None or validation_dataset is None:\n",
    "    print(\"Dataset loading failed. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "NUM_CLASSES = len(train_dataset.class_names) # Get class count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23f9e8-b7a4-4c5a-801d-e1012615e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 2. Load MobileNetV2 and Modify Head ---\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Unlock the base model (you can choose to freeze some layers if needed)\n",
    "base_model.trainable = True\n",
    "\n",
    "# Add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Optional: Add more dense layers\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# --- 3. Compile the Model ---\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',  # Important for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# --- 4. Train the Model ---\n",
    "epochs = 10  # Adjust as needed\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_dataset\n",
    ")\n",
    "\n",
    "# --- 5. Save the Model (Optional) ---\n",
    "model.save('mobilenet_retrained.h5')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
