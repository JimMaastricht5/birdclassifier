{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a689d0-54b5-4d04-b916-29f36f52746c",
   "metadata": {},
   "source": [
    "### Tensor Flow 2-11 notebook\n",
    "\n",
    "Notes: \n",
    "- Notebook should be running with an Nvidia GPU to for top performance\n",
    "- load_img will load a nparray with x, y, 3 color dims.  \n",
    "- If we're just processing one image we will need to np.expand_dims(image, axies=0) to get 1, x, y, 3. The library expects N images in the first dim\n",
    "- should set random seed on tf.random.set_seed(1) for reproduceability \n",
    "- \n",
    "\n",
    "last change 3/6/2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae7bf88-623d-49ab-ae35-c883cbe00ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the libraries for training, testing, validation\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import imagenet_utils  # will decode predictions out of the model into a 4 dim array of N (image num), imageID, label, probability result[0] would be the set of results for image one\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img  # will load img and reshape, usage is load_img(image_name_loc, target_size=input_shape)\n",
    "from tensorflow.keras.utils import plot_model  # Note: usage syntax is plot_model(instantied_model, to_file='', show_shapes=True)\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow_datasets as tfds  # For loading datasets from GCS\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb609827-b297-450f-bc1e-07ebaaf90a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ??? need to switch to dict variables below\n",
    "# Configuration\n",
    "GCS_BUCKET = 'nabirds_filtered'  \n",
    "DATASET_PATH = 'images'  # Relative path within the bucket\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "epochs = 5\n",
    "NUM_CLASSES = None  # determined from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9397c79d-8cba-44fd-b8bc-a367d54bad1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EfficientNetB0: {'image_size': (224, 224), 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.0001}\n",
      "MobileNetV2: {'image_size': (224, 224), 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.0001}\n",
      "MobileNetV3Large: {'image_size': (224, 224), 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.0001}\n",
      "MobileNetV3Small: {'image_size': (224, 224), 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.0001}\n",
      "InceptionV3: {'image_size': (299, 299), 'batch_size': 32, 'epochs': 10, 'learning_rate': 0.0001}\n",
      "EfficientNetB7: {'image_size': (600, 600), 'batch_size': 16, 'epochs': 10, 'learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# define a dictionary for model config and experiment tracking.... \n",
    "model_input_variables = {\n",
    "    \"EfficientNetB0\": {\n",
    "        \"image_size\": (224, 224),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"MobileNetV2\": {\n",
    "        \"image_size\": (224, 224),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "     \"MobileNetV3Large\": { #MobileNetV3 Large will be used to compare accuracy loss with small, prob not a candidate for rasp pi running\n",
    "        \"image_size\": (224, 224),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"MobileNetV3Small\":{ \n",
    "        \"image_size\": (224, 224),\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"InceptionV3\": {\n",
    "        \"image_size\": (299, 299),  # InceptionV3 typically uses 299x299\n",
    "        \"batch_size\": 32,\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    },\n",
    "    \"EfficientNetB7\":{\n",
    "        \"image_size\": (600,600),  # big values!\n",
    "        \"batch_size\": 16, # this is a larger model and the norm seems to be smaller batch sizes for reduced memory use\n",
    "        \"epochs\": 10,\n",
    "        \"learning_rate\": 0.0001,\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f'EfficientNetB0: {model_input_variables[\"EfficientNetB0\"]}')\n",
    "print(f'MobileNetV2: {model_input_variables[\"MobileNetV2\"]}')\n",
    "print(f'MobileNetV3Large: {model_input_variables[\"MobileNetV3Large\"]}')\n",
    "print(f'MobileNetV3Small: {model_input_variables[\"MobileNetV3Small\"]}')\n",
    "print(f'InceptionV3: {model_input_variables[\"InceptionV3\"]}')\n",
    "print(f'EfficientNetB7: {model_input_variables[\"EfficientNetB7\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c6a513-1aad-4763-a833-c0eae28c78bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_results_to_file(filename, start_time, end_time, model_name, batch_size, epochs, image_size, training_accuracy, test_accuracy, training_loss, test_loss):\n",
    "    start_time_str = start_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    end_time_str = end_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    line = f\"{start_time_str},{end_time_str},{model_name},{batch_size},{epochs},{image_size},{training_accuracy},{test_accuracy},{training_loss},{test_loss}\\n\"\n",
    "    if not os.path.exists(filename):      # Check if the file exists, and add a header if it's new\n",
    "        header = \"start_time,end_time,model_name,batch_size,epochs,image_size,training_accuracy,test_accuracy,training_loss,test_loss\\n\"\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(header + line)\n",
    "    else:\n",
    "        with open(filename, \"a\") as f: # or append to existing file\n",
    "            f.write(line)\n",
    "    print(f'experiment tracking updated')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "293b3f33-f2f5-4147-a979-ee49b8c50341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_gcs_dataset(bucket_name, dataset_path, image_size, batch_size):\n",
    "    dataset = None\n",
    "    gcs_dataset_path = f\"gs://{bucket_name}/{dataset_path}\"\n",
    "    try:\n",
    "        dataset = keras.utils.image_dataset_from_directory(gcs_dataset_path, image_size=image_size,\n",
    "            batch_size=batch_size, label_mode='categorical',)  # categorical is for softmax layer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset from GCS: {e}\")    \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3637ff1b-af98-4d1b-ab03-5fcf0051e528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2455 files belonging to 27 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 23:25:39.557629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2025-03-11 23:25:39.557658: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2025-03-11 23:25:39.557686: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (bird-feeder-profiling-2024-2025): /proc/driver/nvidia/version does not exist\n",
      "2025-03-11 23:25:39.560768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 files belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "# split into its own cell so we do not have to repeat this long operation, \n",
    "# ??? will need to be in loop for batch_size changes\n",
    "# took upwards of 5 minutes on 2cpu machine for training data\n",
    "# took another 2 minutes for testing data\n",
    "# process images was cpu bound for another 3 minutes with 50% mem utilization on 8g of ram\n",
    "train_dataset = load_gcs_dataset(GCS_BUCKET, os.path.join(DATASET_PATH, 'train'), IMAGE_SIZE, BATCH_SIZE)\n",
    "validation_dataset = load_gcs_dataset(GCS_BUCKET, os.path.join(DATASET_PATH, 'test'), IMAGE_SIZE, BATCH_SIZE)\n",
    "\n",
    "if train_dataset is None or validation_dataset is None:\n",
    "    print(\"Dataset loading failed. Exiting.\")\n",
    "    exit()\n",
    "num_classes = len(train_dataset.class_names) # Get class count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b23f9e8-b7a4-4c5a-801d-e1012615e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2025-03-11 23:48:34\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 23:48:53.805240: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 120 of 256\n",
      "2025-03-11 23:49:03.801512: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 243 of 256\n",
      "2025-03-11 23:49:04.887589: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/77 [==>...........................] - ETA: 3:50 - loss: 3.3145 - accuracy: 0.1007"
     ]
    }
   ],
   "source": [
    "# ?? code needs to be changed for experiment tracking and different model types\n",
    "\n",
    "##### MobileNetV2 training sample, use for comparision to old model in feeder\n",
    "start_time = time.time()\n",
    "start_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "print(f'Start time: {start_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "###### load mobilenetv2 and modify head\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # unlock top layer for softmax replacement\n",
    "base_model.trainable = True  # Unlock the base model, note this should be changed to freeze some layers per lit review ??\n",
    "\n",
    "# add custom layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)  # Optional: Add more dense layers\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# create the model with Rescaling layer\n",
    "inputs = base_model.input\n",
    "rescaled_inputs = tf.keras.layers.Rescaling(1./255)(inputs)  # normalize pixel values to [0, 1], not sure if this was done in the old mobilenetv2 model\n",
    "x = base_model(rescaled_inputs) # pass the rescaled input through the base model\n",
    "model = Model(inputs=inputs, outputs=predictions) # use the original inputs, this is weird, but how it was done in tutorial...\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',  # Important for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_dataset, epochs=epochs, initial_epoch=0, validation_data=validation_dataset)  # initial epoch=0 is traing from scratch\n",
    "\n",
    "# save model\n",
    "model.save('mobilenet_retrained.h5')\n",
    "\n",
    "# plot results, error here means model did not train\n",
    "acc = history.history['accuracy']\n",
    "test_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "epochs_plt = range(1, len(acc) + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_plt, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs_plt, test_acc, 'r', label='Test accuracy')\n",
    "plt.title('Training and Testing Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_plt, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs_plt, test_loss, 'r', label='Test loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# record training time\n",
    "end_time = time.time()\n",
    "end_time_datetime = datetime.datetime.fromtimestamp(start_time)\n",
    "print(f'End time: {end_time_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b860be-a547-41d1-8db1-c51d4231f316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
